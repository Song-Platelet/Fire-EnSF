{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5oH3E7pgQiN"
      },
      "source": [
        "# Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JReFgFzCgI6L",
        "outputId": "fb91582d-812d-475e-b5e0-b3449357752d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import subprocess\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "from datetime import datetime, timedelta\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='ee-21hs0878')\n",
        "\n",
        "import rasterio\n",
        "import geopandas as gpd\n",
        "from osgeo import gdal, osr\n",
        "from pyproj import Transformer\n",
        "from shapely.ops import unary_union, polygonize\n",
        "from shapely.geometry import box, shape, Point, Polygon, MultiPoint, MultiPolygon, LineString, MultiLineString\n",
        "\n",
        "import landfire\n",
        "\n",
        "from util import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U_yZ-0XjMmU"
      },
      "source": [
        "# Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VUbeX23EjMBf"
      },
      "outputs": [],
      "source": [
        "def extract_band_data(image):\n",
        "    # Create a feature with the extracted data as properties\n",
        "    band_data = image.reduceRegion(\n",
        "        reducer=ee.Reducer.mean(),  # Change reducer if needed (e.g., sum, median)\n",
        "        geometry=point,\n",
        "        scale=1000  # Set the resolution in meters\n",
        "    )\n",
        "    # Return a Feature with the extracted data as properties\n",
        "    return ee.Feature(None, band_data)\n",
        "\n",
        "\n",
        "def convert_id_to_datetime(ids):\n",
        "    # Check if input is a list; if not, wrap it in a list\n",
        "    if isinstance(ids, str):\n",
        "        ids = [ids]\n",
        "\n",
        "    # Process each ID in the list\n",
        "    result = []\n",
        "    for id_string in ids:\n",
        "        # Extract components\n",
        "        year = int(id_string[:4])\n",
        "        month = int(id_string[4:6])\n",
        "        day = int(id_string[6:8])\n",
        "        hour = int(id_string[8:10])\n",
        "        forecast_offset = int(id_string[11:])  # After 'F'\n",
        "\n",
        "        # Base datetime\n",
        "        base_datetime = datetime(year, month, day, hour)\n",
        "\n",
        "        # Add forecast offset\n",
        "        forecast_datetime = base_datetime + timedelta(hours=forecast_offset)\n",
        "\n",
        "        result.append(forecast_datetime)\n",
        "\n",
        "    return result\n",
        "\n",
        "def fju_weather(gdf, fireid, period):\n",
        "    # Load the ImageCollection and filter by date\n",
        "    ex = gdf[gdf['fireID'] == fireid].copy()\n",
        "    clat, clon = ex.iloc[-1, 2:4]\n",
        "    global point\n",
        "    point = ee.Geometry.Point([clon, clat])\n",
        "\n",
        "    start_time = ex.iloc[period,1]\n",
        "\n",
        "    try:\n",
        "        end_time = ex.iloc[period+1,1]\n",
        "    except:\n",
        "        end_time = start_time + timedelta(hours=12)\n",
        "\n",
        "    start_date = (end_time- timedelta(days=3)).strftime(\"%Y-%m-%d\")\n",
        "    end_date = end_time.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    dataset = ee.ImageCollection('NOAA/GFS0P25').filter(\n",
        "        ee.Filter.date(start_date, end_date)\n",
        "    )\n",
        "    # Apply the extraction function to each image in the dataset\n",
        "    band_values = dataset.map(extract_band_data)\n",
        "\n",
        "    # Get the results as a list of dictionaries\n",
        "    band_values_list = band_values.getInfo()['features']\n",
        "\n",
        "    columns = [\"id\",'relative_humidity_2m_above_ground', 'temperature_2m_above_ground', 'total_cloud_cover_entire_atmosphere', \\\n",
        "                        'total_precipitation_surface','u_component_of_wind_10m_above_ground', 'v_component_of_wind_10m_above_ground']\n",
        "    columns = {c:[] for c in columns}\n",
        "\n",
        "    for result in band_values_list:\n",
        "        columns['id'].append(result['id'])\n",
        "        i = ['id']\n",
        "        for key, value in result['properties'].items():\n",
        "            if key in columns.keys():\n",
        "                columns[key].append(value)\n",
        "                i.append(key)\n",
        "        for key in columns.keys():\n",
        "            if key not in i:\n",
        "                columns[key].append(np.nan)\n",
        "    # Print the results\n",
        "    weather_stream = pd.DataFrame(columns)\n",
        "    weather_stream.columns = ['id', 'RH', 'Temp', 'CloudCov', 'HrlyPcp', 'Wind_U', 'Wind_V']\n",
        "    weather_stream['id'] = convert_id_to_datetime(weather_stream['id'])\n",
        "\n",
        "    final_weather = {c:[] for c in ['Datetime', 'RH', 'Temp', 'CloudCov', 'HrlyPcp', 'Wind_U', 'Wind_V']}\n",
        "    current_time = start_time\n",
        "    while current_time <= end_time:\n",
        "        final_weather['Datetime'].append(current_time)\n",
        "        iter_data = weather_stream[weather_stream['id'] == str(current_time)].iloc[:, 1:].copy()\n",
        "\n",
        "        plug_value = iter_data.median()\n",
        "\n",
        "        if weather_stream[weather_stream['id'] == str(current_time)].iloc[0,-1] % 6 == 0:\n",
        "            for c in  ['RH', 'Temp', 'Wind_U', 'Wind_V']:\n",
        "                final_weather[c].append(iter_data.iloc[-1][c])\n",
        "            final_weather['CloudCov'].append(plug_value['CloudCov'])\n",
        "            final_weather['HrlyPcp'].append(plug_value['HrlyPcp'])\n",
        "\n",
        "        else:\n",
        "            for c in ['RH', 'Temp', 'CloudCov', 'HrlyPcp', 'Wind_U', 'Wind_V']:\n",
        "                final_weather[c].append(plug_value[c])\n",
        "\n",
        "        current_time += timedelta(hours=1)\n",
        "    final_weather = pd.DataFrame(final_weather)\n",
        "    final_weather['WindSpd'] = np.sqrt(final_weather['Wind_U']**2 + final_weather['Wind_V']**2)\n",
        "    final_weather['WindDir'] = (270 - np.degrees(np.arctan2(final_weather['Wind_U'], final_weather['Wind_V']))) % 360\n",
        "    final_weather['Time'] = pd.to_datetime(final_weather['Datetime'])\n",
        "    \n",
        "    final_weather['Year'] = final_weather['Datetime'].dt.year\n",
        "    final_weather['Mth'] = final_weather['Datetime'].dt.month\n",
        "    final_weather['Day'] = final_weather['Datetime'].dt.day\n",
        "    final_weather['Hour'] = final_weather['Datetime'].dt.hour\n",
        "    final_weather['Min'] = final_weather['Datetime'].dt.minute\n",
        "    final_weather['Hour'] = final_weather['Hour'].apply(lambda x: f\"{x:02d}\")\n",
        "    final_weather['Min'] = final_weather['Min'].apply(lambda x: f\"{x:02d}\")\n",
        "    final_weather['Time'] = final_weather['Hour'] + final_weather['Min']\n",
        "\n",
        "    final_weather['Temp'] = final_weather['Temp'] * 9/5 + 32         # Celsius to Fahrenheit\n",
        "    final_weather['HrlyPcp'] = final_weather['HrlyPcp'] / 25.4       # Millimeters to Inches\n",
        "    final_weather['WindSpd'] = final_weather['WindSpd'] / 1.609      # km/h to mph\n",
        "\n",
        "    final_weather = final_weather[['Year', 'Mth', 'Day', 'Time', 'Temp', 'RH', 'HrlyPcp', 'WindSpd', 'WindDir', 'CloudCov']]\n",
        "    return final_weather\n",
        "\n",
        "def plot_geometry(geom, edge_color='black', face_color='cyan'):\n",
        "    \"\"\"Plot a Shapely geometry which can be a Polygon or MultiPolygon.\"\"\"\n",
        "    # If geometry is a Polygon, plot it directly.\n",
        "    if geom.geom_type == 'Polygon':\n",
        "        x, y = geom.exterior.xy\n",
        "        plt.plot(x, y, color=edge_color)\n",
        "        plt.fill(x, y, color=face_color, alpha=0.5)\n",
        "    # If geometry is a MultiPolygon, iterate over each component.\n",
        "    elif geom.geom_type == 'MultiPolygon':\n",
        "        for poly in geom.geoms:\n",
        "            plot_geometry(poly, edge_color=edge_color, face_color=face_color)\n",
        "\n",
        "def find_square_boundaries(centroid, width_m):\n",
        "    \"\"\"Computes the boundaries of a square in latitude and longitude.\n",
        "\n",
        "    Args:\n",
        "        centroid (tuple): A tuple containing the latitude and longitude of the centroid.\n",
        "        width_m (float): The width of the square in meters.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (top, bottom, right, left) boundaries in degrees.\n",
        "    \"\"\"\n",
        "    earth_radius = 6_371_000.0\n",
        "    lat, lon = centroid\n",
        "    lat_rad = np.deg2rad(lat)\n",
        "    half_ang_lat = (width_m / 2) / earth_radius\n",
        "    half_ang_lon = (width_m / 2) / (earth_radius * np.cos(lat_rad))\n",
        "    top = lat_rad + half_ang_lat\n",
        "    bottom = lat_rad - half_ang_lat\n",
        "    right = np.deg2rad(lon) + half_ang_lon\n",
        "    left = np.deg2rad(lon) - half_ang_lon\n",
        "\n",
        "    return (\n",
        "        np.rad2deg(top),\n",
        "        np.rad2deg(bottom),\n",
        "        np.rad2deg(right),\n",
        "        np.rad2deg(left),\n",
        "    )\n",
        "\n",
        "def perimeter_input(gdf, fireid:int, period:int, timestep = 60, distance_resolution = 30, \\\n",
        "                    perimeter_resolution = 60, min_ignition_distance = 15, spot_grid_resolution = 15,\\\n",
        "                    spot_probability = 0, spot_ignition_delay = 0, min_spot_distance = 30, \\\n",
        "                    acceleration_on = 1, fill_barriers = 0, spotting_seed = 114514, raws_units = 'English',\\\n",
        "                    num_processors = 1):\n",
        "    gdf = gdf[gdf['fireID'] == fireid]\n",
        "    gdf.reset_index(drop = True, inplace = True)\n",
        "\n",
        "    clat, clon = gdf.iloc[-1, 2:4]\n",
        "    point = ee.Geometry.Point([clon, clat])\n",
        "\n",
        "    datetime_format =  \"'%m %d %H%M'\"\n",
        "    frequency = 'H' # Hourly frequency\n",
        "    start_time = gdf.iloc[period,1]\n",
        "    try:\n",
        "        end_time = gdf.iloc[period+1,1]\n",
        "    except:\n",
        "        end_time = start_time + pd.Timedelta(hours=12)\n",
        "    burn_last = (pd.to_datetime(end_time, format=datetime_format) - pd.Timedelta(minutes=1)).strftime(datetime_format)\n",
        "    burn_periods_data = start_time.strftime(datetime_format) + ' ' + burn_last[-5:]\n",
        "    burn_periods_count = 1\n",
        "\n",
        "    weather_df = fju_weather(gdf, fireid, period)\n",
        "\n",
        "    raws_count = weather_df.shape[0]\n",
        "    # weather_df\n",
        "    formatted_lines = []\n",
        "    for row in range(raws_count):\n",
        "        row = weather_df.iloc[row, :] # Get the current row's data\n",
        "\n",
        "        # Format the current row's data into a string\n",
        "        line_data = (\n",
        "            f\"{row['Year']} {row['Mth']} {row['Day']:02} {row['Time']} \"\n",
        "            f\"{row['Temp']:.0f} {row['RH']:.0f} {row['HrlyPcp']:.0f} {row['WindSpd']:.0f} \"\n",
        "            f\"{row['WindDir']:.0f} {row['CloudCov']:.0f}\\n\"\n",
        "        )\n",
        "        formatted_lines.append(line_data)\n",
        "\n",
        "        # Join all formatted lines into a single string\n",
        "    raws_data = \"\".join(formatted_lines)\n",
        "\n",
        "    image = ee.Image('USGS/SRTMGL1_003')\n",
        "\n",
        "    # Extract elevation at the point\n",
        "    elevation = image.sampleRegions(\n",
        "        collection=ee.FeatureCollection([point]),\n",
        "        scale=30\n",
        "    )\n",
        "\n",
        "    # Print the result\n",
        "    elevation = elevation.getInfo()['features'][0]['properties']['elevation']  * 3.28084\n",
        "\n",
        "    start_time = start_time.strftime(datetime_format)\n",
        "    end_time = end_time.strftime(datetime_format)\n",
        "    farsite_template = \\\n",
        "    f\"\"\"\\\n",
        "FARSITE INPUTS FILE VERSION 1.0\n",
        "FARSITE_START_TIME: {start_time}\n",
        "FARSITE_END_TIME: {end_time}\n",
        "FARSITE_TIMESTEP: {timestep}\n",
        "FARSITE_DISTANCE_RES: {distance_resolution}\n",
        "FARSITE_PERIMETER_RES: {perimeter_resolution}\n",
        "FARSITE_MIN_IGNITION_VERTEX_DISTANCE: {min_ignition_distance}\n",
        "FARSITE_SPOT_GRID_RESOLUTION: {spot_grid_resolution}\n",
        "FARSITE_SPOT_PROBABILITY: {spot_probability}\n",
        "FARSITE_SPOT_IGNITION_DELAY: {spot_ignition_delay}\n",
        "FARSITE_MINIMUM_SPOT_DISTANCE: {min_spot_distance}\n",
        "FARSITE_ACCELERATION_ON: {acceleration_on}\n",
        "FARSITE_FILL_BARRIERS: {fill_barriers}\n",
        "SPOTTING_SEED: {spotting_seed}\n",
        "FARSITE_BURN_PERIODS: {burn_periods_count}\n",
        "{burn_periods_data}\n",
        "\n",
        "FUEL_MOISTURES_DATA: 25\n",
        "0 6 7 8 60 90\n",
        "91 6 7 8 60 90\n",
        "93 6 7 8 60 90\n",
        "98 6 7 8 60 90\n",
        "99 6 7 8 60 90\n",
        "101 6 7 8 60 90\n",
        "102 6 7 8 60 90\n",
        "104 6 7 8 60 90\n",
        "121 6 7 8 60 90\n",
        "122 6 7 8 60 90\n",
        "141 6 7 8 60 90\n",
        "142 6 7 8 60 90\n",
        "143 6 7 8 60 90\n",
        "145 6 7 8 60 90\n",
        "147 6 7 8 60 90\n",
        "1 6 7 8 60 90\n",
        "2 6 7 8 60 90\n",
        "5 6 7 8 60 90\n",
        "181 6 7 8 60 90\n",
        "182 6 7 8 60 90\n",
        "183 6 7 8 60 90\n",
        "185 6 7 8 60 90\n",
        "186 6 7 8 60 90\n",
        "188 6 7 8 60 90\n",
        "189 6 7 8 60 90\n",
        "RAWS_ELEVATION: {elevation}\n",
        "RAWS_UNITS: {raws_units}\n",
        "\n",
        "RAWS: {raws_count}\n",
        "{raws_data}\n",
        "FOLIAR_MOISTURE_CONTENT: 100\n",
        "CROWN_FIRE_METHOD: Finney\n",
        "NUMBER_PROCESSORS: {num_processors}\n",
        "\n",
        "\n",
        "FLAMELENGTH:\n",
        "SPREADRATE:\n",
        "INTENSITY:\n",
        "CROWNSTATE:\n",
        "    \"\"\"\n",
        "    file_path = rf\"{fireid}\\{period}\\para.input\"\n",
        "    farsite_template = farsite_template.replace(\"'\", \"\")\n",
        "    # Write the content to the file\n",
        "    try:\n",
        "        with open(file_path, 'w') as f:\n",
        "            f.write(farsite_template)\n",
        "        print(f\"Successfully wrote FARSITE input to: {file_path}\")\n",
        "    except IOError as e:\n",
        "        print(f\"Error writing file {file_path}: {e}\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: Missing parameter {e} in the params dictionary.\")\n",
        "    return farsite_template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbwOqHrGgSRM"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzSFRzf4gj-g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-122.91400816630518 38.37926961378655 -122.45397667451162 38.73899825615404\n"
          ]
        }
      ],
      "source": [
        "gdf = gpd.read_file(r\"LargeFires_2012-2020.gpkg\")\n",
        "gdf = gdf[['fireID', 'time', 'clat', 'clon', 'farea', 'geometry']]\n",
        "gdf['time'] = pd.to_datetime(gdf['time'])\n",
        "\n",
        "time_limit = gdf[['fireID', 'time']].copy()\n",
        "time_limit = time_limit[time_limit['time'] < '2016/07/01']\n",
        "time_limit = time_limit['fireID'].unique()\n",
        "\n",
        "duration_filter = gdf.groupby('fireID').count().reset_index().copy()\n",
        "duration_filter = duration_filter[(duration_filter['time'] > 10) & (duration_filter['time'] < 20)]['fireID'].to_list()\n",
        "\n",
        "area_filter = gdf[['fireID', 'farea']].copy()\n",
        "area_filter = area_filter[area_filter.duplicated(keep=False)]\n",
        "area_filter = area_filter['fireID'].unique()\n",
        "\n",
        "multipolygon_fireIDs = set(gdf[gdf.geometry.geom_type == 'MultiPolygon']['fireID'].unique())\n",
        "\n",
        "gdf = gdf[(~gdf['fireID'].isin(time_limit))\n",
        "        & (gdf['fireID'].isin(duration_filter))\n",
        "        & (~gdf['fireID'].isin(area_filter))\n",
        "        & (~gdf['fireID'].isin(multipolygon_fireIDs))]\n",
        "\n",
        "# fireid_list = gdf['fireID'].unique()\n",
        "fireid_list = [3173]\n",
        "for fireid in fireid_list:\n",
        "    # create_folder(str(fireid))\n",
        "    \n",
        "    temp_df = gdf[gdf['fireID'] == fireid].copy()\n",
        "    clat, clon = temp_df.iloc[-1, 2:4]\n",
        "\n",
        "    SQUARE_WIDTH_M = 40000\n",
        "    LANDFIRE_LAYERS = [\n",
        "        \"ELEV2020\", \"SLPD2020\", \"ASP2020\",\n",
        "        \"220F40_22\", \"220CC_22\", \"220CH_22\",\n",
        "        \"220CBH_22\", \"220CBD_22\"\n",
        "    ]\n",
        "    OUTPUT_ZIP_FILE = \"lf_data.zip\"\n",
        "    OUTPUT_RASTER_DIR = \"lf_rasters\"\n",
        "\n",
        "    top, bottom, right, left = find_square_boundaries((clat, clon), SQUARE_WIDTH_M)\n",
        "    \n",
        "    bbox_str = f\"{left} {bottom} {right} {top}\"  # min_x min_y max_x max_y\n",
        "    print(bbox_str)\n",
        "\n",
        "    break\n",
        "    lf = landfire.Landfire(bbox=bbox_str)\n",
        "    lf.request_data(\n",
        "        layers=LANDFIRE_LAYERS,\n",
        "        output_path=OUTPUT_ZIP_FILE\n",
        "    )\n",
        "\n",
        "    os.makedirs(OUTPUT_RASTER_DIR, exist_ok=True)\n",
        "    with zipfile.ZipFile(OUTPUT_ZIP_FILE, \"r\") as z:\n",
        "        z.extractall(OUTPUT_RASTER_DIR)\n",
        "\n",
        "    tif_list = glob.glob(os.path.join(OUTPUT_RASTER_DIR, \"*.tif\"))\n",
        "    if not tif_list:\n",
        "        raise RuntimeError(f\"No .tif files found in {OUTPUT_RASTER_DIR}\")\n",
        "    tif_path = tif_list[0]\n",
        "    print(f\"âœ… First LANDFIRE raster found: {tif_path}\")\n",
        "\n",
        "    gdal.AllRegister()\n",
        "    output_file = rf'{fireid}\\{fireid}.lcp'\n",
        "\n",
        "    ds = gdal.Open(tif_path)\n",
        "    if ds is None:\n",
        "        print(f\"Unable to open {tif_path}\")\n",
        "    else:\n",
        "        # Get the GDAL driver for LCP format\n",
        "        driver = gdal.GetDriverByName('LCP')\n",
        "        if driver is None:\n",
        "            print(\"LCP driver is not available in your GDAL build.\")\n",
        "        else:\n",
        "            # Optional: set creation options (adjust these as needed for your data)\n",
        "            creation_options = [\n",
        "                'ELEVATION_UNIT=METERS',      # Can also be FEET if applicable\n",
        "                'SLOPE_UNIT=DEGREES',        # Use PERCENT if needed\n",
        "                'ASPECT_UNIT=AZIMUTH_DEGREES', # Other valid values: GRASS_CATEGORIES, etc.\n",
        "                # 'FUEL_MODEL_OPTION=NO_CUSTOM_AND_NO_FILE',  # Uncomment if needed\n",
        "            ]\n",
        "\n",
        "            # Create a copy in the LCP format\n",
        "            out_ds = driver.CreateCopy(output_file, ds, options=creation_options)\n",
        "            if out_ds is None:\n",
        "                print(\"Conversion to LCP failed.\")\n",
        "            else:\n",
        "                print(f\"Conversion to LCP successful: {output_file}\")\n",
        "                out_ds = None # Close the output dataset\n",
        "        ds = None # Close the input dataset\n",
        "\n",
        "    \n",
        "    # Open the first raster to get its CRS\n",
        "    ds = gdal.Open(output_file)\n",
        "    proj = ds.GetProjection()\n",
        "    srs = osr.SpatialReference()\n",
        "    srs.ImportFromWkt(proj)\n",
        "\n",
        "    crs_proj = srs.ExportToProj4()\n",
        "    ds = None  # Close the dataset\n",
        "    period, _ = temp_df.shape\n",
        "    # Fire boundary processing\n",
        "    for i in range(period):\n",
        "        current_folder = rf'{fireid}\\{i}'\n",
        "        create_folder(current_folder)\n",
        "        OUTPUT_SHP_DIR = rf\"{fireid}\\{i}\\fire_boundary_albers\"\n",
        "        OUTPUT_SHP_FILE = rf\"{fireid}\\{i}\\fire_boundary.shp\"\n",
        "        \n",
        "        shp_geom = temp_df.iloc[i, -1]\n",
        "\n",
        "        fire_boundary_gdf = gpd.GeoDataFrame(geometry=[shp_geom], crs=\"EPSG:4326\")\n",
        "        fire_boundary_gdf = fire_boundary_gdf.to_crs(crs_proj)  # Use PROJ string directly\n",
        "        fire_boundary_gdf.to_file(OUTPUT_SHP_FILE)\n",
        "        # Save reprojected shapefile\n",
        "        perimeter_input(gdf, fireid, i)\n",
        "\n",
        "    if os.path.isfile(OUTPUT_ZIP_FILE):\n",
        "        os.remove(OUTPUT_ZIP_FILE)\n",
        "        print(f\"Deleted file: {OUTPUT_ZIP_FILE}\")\n",
        "    else:\n",
        "        print(f\"No such file to delete: {OUTPUT_ZIP_FILE}\")\n",
        "    if os.path.isdir(OUTPUT_RASTER_DIR):\n",
        "        shutil.rmtree(OUTPUT_RASTER_DIR)\n",
        "        print(f\"Deleted directory and all contents: {OUTPUT_RASTER_DIR}\")\n",
        "    else:\n",
        "        print(f\"No such directory to delete: {OUTPUT_RASTER_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Geographic 2D CRS: EPSG:4326>\n",
              "Name: WGS 84\n",
              "Axis Info [ellipsoidal]:\n",
              "- Lat[north]: Geodetic latitude (degree)\n",
              "- Lon[east]: Geodetic longitude (degree)\n",
              "Area of Use:\n",
              "- name: World.\n",
              "- bounds: (-180.0, -90.0, 180.0, 90.0)\n",
              "Datum: World Geodetic System 1984 ensemble\n",
              "- Ellipsoid: WGS 84\n",
              "- Prime Meridian: Greenwich"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gdf = gpd.read_file(r\"LargeFires_2012-2020.gpkg\", engine = 'pyogrio')\n",
        "gdf = gdf[['fireID', 'time', 'clat', 'clon', 'farea', 'geometry']]\n",
        "gdf['time'] = pd.to_datetime(gdf['time'])\n",
        "\n",
        "time_limit = gdf[['fireID', 'time']].copy()\n",
        "time_limit = time_limit[time_limit['time'] < '2016/07/01']\n",
        "time_limit = time_limit['fireID'].unique()\n",
        "\n",
        "duration_filter = gdf.groupby('fireID').count().reset_index().copy()\n",
        "duration_filter = duration_filter[(duration_filter['time'] > 10) & (duration_filter['time'] < 20)]['fireID'].to_list()\n",
        "\n",
        "area_filter = gdf[['fireID', 'farea']].copy()\n",
        "area_filter = area_filter[area_filter.duplicated(keep=False)]\n",
        "area_filter = area_filter['fireID'].unique()\n",
        "\n",
        "multipolygon_fireIDs = set(gdf[gdf.geometry.geom_type == 'MultiPolygon']['fireID'].unique())\n",
        "\n",
        "gdf = gdf[(~gdf['fireID'].isin(time_limit))\n",
        "        & (gdf['fireID'].isin(duration_filter))\n",
        "        & (~gdf['fireID'].isin(area_filter))\n",
        "        & (~gdf['fireID'].isin(multipolygon_fireIDs))]\n",
        "\n",
        "fireid = 1819\n",
        "\n",
        "temp_df = gdf[gdf['fireID'] == fireid].reset_index().copy()\n",
        "\n",
        "gdf.crs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPSG:4326\n"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_5oH3E7pgQiN",
        "1U_yZ-0XjMmU",
        "f9VNKLthRSbP"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
