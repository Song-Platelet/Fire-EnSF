{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b27cc2b1",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dda991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f3bc1d",
   "metadata": {},
   "source": [
    "# Coarse Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080bd772",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_alpha = lambda t: 1 - (1-eps_alpha)*t\n",
    "\n",
    "# conditional sigma^2\n",
    "cond_sigma_sq = lambda t: eps_beta + t * (1 - eps_beta)\n",
    "\n",
    "# drift function of forward SDE\n",
    "f = lambda t: -(1-eps_alpha) / cond_alpha(t)\n",
    "\n",
    "# diffusion function of forward SDE\n",
    "g_sq = lambda t: 1 - 2 * f(t) * cond_sigma_sq(t)\n",
    "g = lambda t: np.sqrt(g_sq(t))\n",
    "\n",
    "# generate sample with reverse SDE\n",
    "def reverse_SDE(x0, score_likelihood=None, time_steps=100,\n",
    "                drift_fun=f, diffuse_fun=g, alpha_fun=cond_alpha, sigma2_fun=cond_sigma_sq,  save_path=False):\n",
    "    # x_T: sample from standard Gaussian\n",
    "    # x_0: target distribution to sample from\n",
    "\n",
    "    # reverse SDE sampling process\n",
    "    # N1 = x_T.shape[0]\n",
    "    # N2 = x0.shape[0]\n",
    "    # d = x_T.shape[1]\n",
    "\n",
    "    # Generate the time mesh\n",
    "    dt = 1.0/time_steps\n",
    "\n",
    "    # Initialization\n",
    "    xt = torch.randn(ensemble_size, n_dim, device=device)\n",
    "    t = 1.0\n",
    "\n",
    "    # define storage\n",
    "    if save_path:\n",
    "        path_all = [xt]\n",
    "        t_vec = [t]\n",
    "\n",
    "    # forward Euler sampling\n",
    "    for i in range(time_steps):\n",
    "        # prior score evaluation\n",
    "        alpha_t = alpha_fun(t)\n",
    "        sigma2_t = sigma2_fun(t)\n",
    "\n",
    "        # Evaluate the diffusion term\n",
    "        diffuse = diffuse_fun(t)\n",
    "\n",
    "        # Evaluate the drift term\n",
    "        # drift = drift_fun(t)*xt - diffuse**2 * score_eval\n",
    "\n",
    "        # Update\n",
    "        if score_likelihood is not None:\n",
    "            xt += - dt*( drift_fun(t)*xt + diffuse**2 * ( (xt - alpha_t*x0)/sigma2_t) - diffuse**2 * score_likelihood(xt, t) ) \\\n",
    "                  + np.sqrt(dt)*diffuse*torch.randn_like(xt)\n",
    "        else:\n",
    "            xt += - dt*( drift_fun(t)*xt + diffuse**2 * ( (xt - alpha_t*x0)/sigma2_t) ) + np.sqrt(dt)*diffuse*torch.randn_like(xt)\n",
    "\n",
    "        # Store the state in the path\n",
    "        if save_path:\n",
    "            path_all.append(xt)\n",
    "            t_vec.append(t)\n",
    "\n",
    "        # update time\n",
    "        t = t - dt\n",
    "\n",
    "    if save_path:\n",
    "        return path_all, t_vec\n",
    "    else:\n",
    "        return xt\n",
    "\n",
    "# the lorenz drift\n",
    "lorenz96_drift = lambda x: 2*x\n",
    "\n",
    "# lorenz system\n",
    "n_dim = 2500\n",
    "SDE_sigma = 0.5\n",
    "\n",
    "# filtering setup\n",
    "dt = 0.05\n",
    "filtering_steps = 30\n",
    "\n",
    "# observation sigma\n",
    "obs_sigma = 0.1\n",
    "\n",
    "####################################################################\n",
    "# EnSF setup\n",
    "\n",
    "# ensemble size\n",
    "ensemble_size = 100\n",
    "\n",
    "# forward Euler step\n",
    "euler_steps = 100\n",
    "\n",
    "# damping function(tau(0) = 1;  tau(1) = 0;)\n",
    "g_tau = lambda t: 1-t\n",
    "\n",
    "# computation setting\n",
    "torch.set_default_dtype(torch.float64) # half precision\n",
    "device = torch.device('cuda')\n",
    "\n",
    "eps_alpha_list, eps_beta_list = np.round(np.arange(0.1, 1, 0.1), 1), np.round(np.arange(0.1, 1, 0.1), 1)\n",
    "\n",
    "tune_result = []\n",
    "\n",
    "for eps_alpha in tqdm(eps_alpha_list):\n",
    "    for eps_beta in eps_beta_list:\n",
    "        ####################################################################\n",
    "        ####################################################################\n",
    "        # initial state\n",
    "        angles = np.linspace(-2 * np.pi, 2 * np.pi, int(n_dim/2), endpoint=False)\n",
    "        x = 1.00 * np.cos(angles)\n",
    "        y = 1.00 * np.sin(angles)\n",
    "        state_target = torch.tensor(np.vstack((x, y)).T.flatten(), device=device)\n",
    "\n",
    "        # filtering initial ensemble\n",
    "        x = 1.15 * np.cos(angles)\n",
    "        y = 1.05 * np.sin(angles)\n",
    "        x_prop = torch.tensor(np.vstack((x, y)).T.flatten(), device=device) # Initial set up\n",
    "\n",
    "        x_state = x_prop.repeat(ensemble_size, 1) + 0.1 * torch.randn(ensemble_size, n_dim, device=device)\n",
    "\n",
    "        torch.manual_seed(114514)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        rmse_sf = []\n",
    "        rmse_o = []\n",
    "\n",
    "        for i in range(filtering_steps):\n",
    "            x_prop += dt*lorenz96_drift(x_prop)\n",
    "            # prediction step ############################################\n",
    "            # state forward in time\n",
    "            x_state += dt*lorenz96_drift(x_state) + np.sqrt(dt)*SDE_sigma*torch.randn_like(x_state)\n",
    "\n",
    "            # ensemble prediction (Ground Truth)\n",
    "            state_target += dt*lorenz96_drift(state_target) + np.sqrt(dt)*SDE_sigma*torch.randn_like(state_target)\n",
    "\n",
    "            # update step ################################################\n",
    "            # get observation\n",
    "            # obs = torch.atan(state_target) + torch.randn_like(state_target)*obs_sigma\n",
    "            obs = 0.25 * state_target + torch.randn_like(state_target) * obs_sigma\n",
    "\n",
    "            # define likelihood score\n",
    "            # obs: (d)\n",
    "            # xt: (ensemble, d)\n",
    "            # score_likelihood = lambda xt, t: -(torch.atan(xt) - obs)/obs_sigma**2 * (1./(1. + xt**2)) * g_tau(t)\n",
    "            score_likelihood = lambda xt, t: -(0.25*xt - obs) / obs_sigma**2 * g_tau(t) * 0.25\n",
    "\n",
    "            # generate posterior sample\n",
    "            x_state = reverse_SDE(x0=x_state, score_likelihood=score_likelihood, time_steps=euler_steps)\n",
    "\n",
    "            # get state estimates\n",
    "            x_est = torch.mean(x_state, dim=0)\n",
    "\n",
    "            # get rmse\n",
    "            rmse_ensf = compute_rmse(x_est.reshape(-1,2).cpu().numpy(), state_target.reshape(-1,2).cpu().numpy())#torch.sqrt(torch.mean((x_est - state_target)**2)).item()\n",
    "            rmse_ori = compute_rmse(x_est.reshape(-1,2).cpu().numpy(), (4*obs).reshape(-1,2).cpu().numpy())#torch.sqrt(torch.mean((x_prop - state_target)**2)).item()\n",
    "\n",
    "            rmse_sf.append(rmse_ensf)\n",
    "            rmse_o.append(rmse_ori)\n",
    "\n",
    "            if x_state.device.type == 'cuda':\n",
    "                torch.cuda.current_stream().synchronize() #Wait for all kernels in all streams on a CUDA device to complete.\n",
    "            if rmse_ensf > 1000:\n",
    "                print('diverge!')\n",
    "                break\n",
    "\n",
    "        tune_result.append([eps_alpha, eps_beta, np.mean(rmse_sf[1:]), np.mean(rmse_o[1:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da97dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(tune_result, columns = ['eps_alpha', 'eps_beta', 'rmse_sf','rmse_o'])\n",
    "\n",
    "heatmap_data = data.pivot_table(index='eps_alpha', columns='eps_beta', values='rmse_sf')\n",
    "\n",
    "def tune_heatmap(heatmap_data, title):\n",
    "    plt.figure(figsize = (8*1.25, 7*1.25))\n",
    "    ax = sns.heatmap(\n",
    "        heatmap_data,\n",
    "        annot=True,\n",
    "        fmt=\".3f\",\n",
    "        cmap='Blues_r', # 'viridis' or 'plasma' are good perceptually uniform options\n",
    "        linewidths=1, # Slightly thicker lines\n",
    "        linecolor='white', # White lines for good contrast\n",
    "        annot_kws={\"size\": 16, \"weight\": \"bold\"} # Bold annotations\n",
    "    )\n",
    "\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_label(\n",
    "        'RMSE - Haversine Distance (km)',\n",
    "        size=20,\n",
    "        weight='bold'\n",
    "    )\n",
    "    cbar.ax.tick_params(labelsize=14)  # Set tick font size\n",
    "\n",
    "    # Find the 3 lowest values\n",
    "    # We use a trick with unstacking the dataframe to easily sort the values\n",
    "    sorted_vals = heatmap_data.unstack().sort_values()\n",
    "    lowest_three = sorted_vals.head(3)\n",
    "\n",
    "    # Add circles around the 3 lowest values\n",
    "    for idx in lowest_three.index:\n",
    "        # Get the row and column index\n",
    "        col, row = idx\n",
    "        col_idx = heatmap_data.columns.get_loc(col)\n",
    "        row_idx = heatmap_data.index.get_loc(row)\n",
    "\n",
    "        # Add a rectangle patch\n",
    "        rect = Rectangle((col_idx, row_idx), 1, 1, color='red', linewidth=2.5, fill=False, zorder=5)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel(r'$\\epsilon_\\beta$', fontsize=18)\n",
    "    plt.ylabel(r'$\\epsilon_\\alpha$', fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(title, bbox_inches='tight')\n",
    "    plt.show()\n",
    "tune_heatmap(heatmap_data, 'vs_gt.pdf')\n",
    "heatmap_data = data.pivot_table(index='eps_alpha', columns='eps_beta', values='rmse_o')\n",
    "tune_heatmap(heatmap_data, 'vs_obs.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbde44a",
   "metadata": {},
   "source": [
    "# Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af22216",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_alpha = lambda t: 1 - (1-eps_alpha)*t\n",
    "\n",
    "# conditional sigma^2\n",
    "cond_sigma_sq = lambda t: eps_beta + t * (1 - eps_beta)\n",
    "\n",
    "# drift function of forward SDE\n",
    "f = lambda t: -(1-eps_alpha) / cond_alpha(t)\n",
    "\n",
    "# diffusion function of forward SDE\n",
    "g_sq = lambda t: 1 - 2 * f(t) * cond_sigma_sq(t)\n",
    "g = lambda t: np.sqrt(g_sq(t))\n",
    "\n",
    "# damping function(tau(0) = 1;  tau(1) = 0;)\n",
    "g_tau = lambda t: 1-t\n",
    "\n",
    "# computation setting\n",
    "torch.set_default_dtype(torch.float64) # half precision\n",
    "device = torch.device('cuda')\n",
    "\n",
    "eps_alpha_list, eps_beta_list = np.round(np.arange(0.8, 1, 0.01), 2), np.round(np.arange(0.01, 0.2, 0.01), 2)\n",
    "\n",
    "tune_result = []\n",
    "\n",
    "for eps_alpha in tqdm(eps_alpha_list):\n",
    "    for eps_beta in eps_beta_list:\n",
    "        ####################################################################\n",
    "        ####################################################################\n",
    "        # initial state\n",
    "        angles = np.linspace(-2 * np.pi, 2 * np.pi, int(n_dim/2), endpoint=False)\n",
    "        x = 1.00 * np.cos(angles)\n",
    "        y = 1.00 * np.sin(angles)\n",
    "        state_target = torch.tensor(np.vstack((x, y)).T.flatten(), device=device)\n",
    "\n",
    "        # filtering initial ensemble\n",
    "        x = 1.15 * np.cos(angles)\n",
    "        y = 1.05 * np.sin(angles)\n",
    "        x_prop = torch.tensor(np.vstack((x, y)).T.flatten(), device=device) # Initial set up\n",
    "\n",
    "        x_state = x_prop.repeat(ensemble_size, 1) + 0.1 * torch.randn(ensemble_size, n_dim, device=device)\n",
    "\n",
    "        torch.manual_seed(114514)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        rmse_sf = []\n",
    "        rmse_o = []\n",
    "\n",
    "        for i in range(filtering_steps):\n",
    "            x_prop += dt*lorenz96_drift(x_prop)\n",
    "            # prediction step ############################################\n",
    "            # state forward in time\n",
    "            x_state += dt*lorenz96_drift(x_state) + np.sqrt(dt)*SDE_sigma*torch.randn_like(x_state)\n",
    "\n",
    "            # ensemble prediction (Ground Truth)\n",
    "            state_target += dt*lorenz96_drift(state_target) + np.sqrt(dt)*SDE_sigma*torch.randn_like(state_target)\n",
    "\n",
    "            # update step ################################################\n",
    "            # get observation\n",
    "            # obs = torch.atan(state_target) + torch.randn_like(state_target)*obs_sigma\n",
    "            obs = 0.25 * state_target + torch.randn_like(state_target) * obs_sigma\n",
    "\n",
    "            # define likelihood score\n",
    "            # obs: (d)\n",
    "            # xt: (ensemble, d)\n",
    "            # score_likelihood = lambda xt, t: -(torch.atan(xt) - obs)/obs_sigma**2 * (1./(1. + xt**2)) * g_tau(t)\n",
    "            score_likelihood = lambda xt, t: -(0.25*xt - obs) / obs_sigma**2 * g_tau(t) * 0.25\n",
    "\n",
    "            # generate posterior sample\n",
    "            x_state = reverse_SDE(x0=x_state, score_likelihood=score_likelihood, time_steps=euler_steps)\n",
    "\n",
    "            # get state estimates\n",
    "            x_est = torch.mean(x_state, dim=0)\n",
    "\n",
    "            # get rmse\n",
    "            rmse_ensf = compute_rmse(x_est.reshape(-1,2).cpu().numpy(), state_target.reshape(-1,2).cpu().numpy())#torch.sqrt(torch.mean((x_est - state_target)**2)).item()\n",
    "            rmse_ori = compute_rmse(x_est.reshape(-1,2).cpu().numpy(), (4*obs).reshape(-1,2).cpu().numpy())#torch.sqrt(torch.mean((x_prop - state_target)**2)).item()\n",
    "\n",
    "            rmse_sf.append(rmse_ensf)\n",
    "            rmse_o.append(rmse_ori)\n",
    "\n",
    "            if x_state.device.type == 'cuda':\n",
    "                torch.cuda.current_stream().synchronize() #Wait for all kernels in all streams on a CUDA device to complete.\n",
    "            if rmse_ensf > 1000:\n",
    "                print('diverge!')\n",
    "                break\n",
    "\n",
    "        tune_result.append([eps_alpha, eps_beta, np.mean(rmse_sf[1:]), np.mean(rmse_o[1:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d197ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([[1,1,5,8],[1,2,3,6],[2,1,2,2],[2,2,15,10]], columns = ['eps_alpha', 'eps_beta', 'rmse_sf','rmse_o'])\n",
    "\n",
    "xi = np.linspace(data.eps_alpha.min(), data.eps_alpha.max(), 100)\n",
    "yi = np.linspace(data.eps_beta.min(), data.eps_beta.max(), 100)\n",
    "zi = griddata((data.eps_alpha, data.eps_beta), data.rmse_sf, (xi[None,:], yi[:,None]), method='cubic')\n",
    "\n",
    "# 3. Find the coordinates of the best score\n",
    "# This finds the point with the lowest RMSE to highlight it on the plot.\n",
    "min_rmse_idx = np.argmin(data.rmse_sf)\n",
    "min_alpha = data.eps_alpha[min_rmse_idx]\n",
    "min_beta = data.eps_beta[min_rmse_idx]\n",
    "\n",
    "# 4. Generate the plot\n",
    "# Create the filled contour plot with a reversed 'viridis' colormap\n",
    "# ('viridis_r') so that lower values (better RMSE) are darker.\n",
    "fig, ax = plt.subplots(figsize=(7.5, 5))\n",
    "sc = ax.contourf(xi, yi, zi, levels=15, cmap='viridis_r')\n",
    "\n",
    "# Add a color bar to show the RMSE scale.\n",
    "# Add the color bar with the label and fontsize\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label('RMSE - Haversine Distance (km)', fontsize=18)\n",
    "\n",
    "# You can also set the tick label size\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "# Add contour lines for better readability.\n",
    "ax.contour(xi, yi, zi, levels=15, colors='white', alpha=0.5, linewidths=0.5)\n",
    "\n",
    "# 5. Mark the optimal point\n",
    "# Place a red star on the best hyperparameter combination.\n",
    "ax.scatter(min_alpha, min_beta, marker = 'X', color = 'red', s = 100,\n",
    "         label='Optimal Point\\n'\n",
    "               rf'$\\epsilon_\\alpha$ = {min_alpha}'\n",
    "               '\\n'\n",
    "               rf'$\\epsilon_\\beta$ = {min_beta}'\n",
    "               '\\n'\n",
    "               f'RMSE: {data.rmse_sf.min():.2f}'\n",
    "               )\n",
    "\n",
    "legend = ax.legend(frameon=True, loc='best', fontsize=14) # 'best' tries to find the least obstructive location\n",
    "legend.get_frame().set_edgecolor('gray') # Add a light border to the legend\n",
    "\n",
    "# 6. Add labels and a title for clarity\n",
    "plt.xlabel(r'$\\epsilon_\\alpha$', fontsize=18)\n",
    "plt.ylabel(r'$\\epsilon_\\beta$', fontsize=18)\n",
    "\n",
    "# 7. Display the plot\n",
    "plt.savefig('vs_mgt.pdf', bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.8.17)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
